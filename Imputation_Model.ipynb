{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD_fjTWkfs87"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "from sklearn.linear_model import Ridge\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Missing Values Generation\n",
        "df_pems=pd.read_csv(\"/content/drive/MyDrive/MISSING_DATASET/vel.csv\",header=None)\n",
        "\n",
        "for node in range(df_pems.shape[1]):\n",
        "  df_pems[node]=np.where(df_pems[node]==0,df_pems[node].mean(),df_pems[node])\n",
        "\n",
        "TOTAL_ARR=[]\n",
        "for node in tqdm(range(df_pems.shape[1])):\n",
        "    arr=[]\n",
        "    for j in range(119):\n",
        "        frr=[]\n",
        "        for k in range(288):\n",
        "            frr.append(df_pems[node].values[288*j+k])\n",
        "        arr.append(frr)\n",
        "    TOTAL_ARR.append(arr)\n",
        "\n",
        "TOTAL_ARR=np.array(TOTAL_ARR)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## RANDOM MISSING VALUES\n",
        "dense_tensor=TOTAL_ARR\n",
        "dim = dense_tensor.shape\n",
        "missing_rate = 0.8\n",
        "sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
        "if np.isnan(sparse_tensor).any() == False:\n",
        "    ind = sparse_tensor != 0\n",
        "    pos_obs = np.where(ind)\n",
        "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
        "elif np.isnan(sparse_tensor).any() == True:\n",
        "    pos_test = np.where((dense_tensor != 0) & (np.isnan(sparse_tensor)))\n",
        "    ind = ~np.isnan(sparse_tensor)\n",
        "    pos_obs = np.where(ind)\n",
        "    sparse_tensor[np.isnan(sparse_tensor)] = 0\n",
        "num_obs = len(pos_obs[0])\n",
        "dense_test = dense_tensor[pos_test]\n",
        "i,j,k=pos_test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ## NON-random missing values\n",
        "# dense_tensor = TOTAL_ARR\n",
        "# dim = dense_tensor.shape\n",
        "# missing_rate = 0.8\n",
        "# sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1])[:, :, np.newaxis] + 0.5 - missing_rate)\n",
        "# ##\n",
        "# if np.isnan(sparse_tensor).any() == False:\n",
        "#     ind = sparse_tensor != 0\n",
        "#     pos_obs = np.where(ind)\n",
        "#     pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
        "# elif np.isnan(sparse_tensor).any() == True:\n",
        "#     pos_test = np.where((dense_tensor != 0) & (np.isnan(sparse_tensor)))\n",
        "#     ind = ~np.isnan(sparse_tensor)\n",
        "#     pos_obs = np.where(ind)\n",
        "#     sparse_tensor[np.isnan(sparse_tensor)] = 0\n",
        "# num_obs = len(pos_obs[0])\n",
        "# dense_test = dense_tensor[pos_test]\n",
        "\n",
        "DATAPOINTS=[]\n",
        "NODE=[]\n",
        "for m in tqdm(range(len(i))):\n",
        "  DATAPOINTS.append(288*j[m]+k[m])\n",
        "  NODE.append(i[m])\n",
        "\n",
        "d=pd.DataFrame([NODE,DATAPOINTS,dense_test])\n",
        "\n",
        "d_transpose=d.T\n",
        "d_transpose.to_csv(\"/content/drive/MyDrive/MTERLA_FINAL/ORIGINAL_DATAPOINTS_0.8.csv\",index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "uQAK6ic2hOVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQ3RfuvhjfnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SJontf8HjQQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## FOR REPLACING MISSING VALUES\n",
        "df_datapoints=pd.read_csv(\"/content/drive/MyDrive/MTERLA_FINAL/ORIGINAL_DATAPOINTS_0.8.csv\")\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/MISSING_DATASET/vel.csv\",header=None)\n",
        "adj=np.load(\"/content/drive/MyDrive/MISSING_DATASET/MTRLA_ADJACENCY_MATRIX.npy\")\n",
        "I=np.identity(207)\n",
        "adj=adj-I\n",
        "adj=np.where(adj!=0,1,0)\n",
        "adj=np.mat(adj)\n",
        "i,j=np.where(adj!=0)\n",
        "i=list(i)\n",
        "d=np.sum(adj,axis=1)"
      ],
      "metadata": {
        "id": "HfQ5ARtLjQWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## IMPUTATION OF THE MISSING VALUES\n",
        "Result=pd.DataFrame([],columns=[\"ACTUAL_SPEED\",\"PREDICTED_SPEED\"])\n",
        "SPEED=[]\n",
        "ACTUAL=[]\n",
        "for vod in tqdm(range(df_datapoints.shape[0])):\n",
        "  if vod<Result.shape[0]:\n",
        "    pass\n",
        "  else:\n",
        "    d_frame=validation_data(df_datapoints[str(0)].values[vod],df_datapoints[str(1)].values[vod])\n",
        "    SPEED.append(d_frame['Replaced_speed'].values[0])\n",
        "    ACTUAL.append(df_datapoints[str(2)].values[vod])\n",
        "    r_dataframe=pd.DataFrame([[df_datapoints[str(2)].values[vod],d_frame['Replaced_speed'].values[0]]],columns=[\"ACTUAL_SPEED\",\"PREDICTED_SPEED\"])\n",
        "    Result=pd.concat([Result,r_dataframe],ignore_index=True)\n",
        "    Result.to_csv(\"/content/drive/MyDrive/MISSING_VALUE_RESULTS_MTERLA/NEW_RESULTS_0.2.csv\",index=False)"
      ],
      "metadata": {
        "id": "Ce7SUUNKmSaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_dAPnmRFmcz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EV3nEoHXmhRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "synSeL_nmw5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQWurWE5mw8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a3KMrZgXmw_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WVhqkLkamxC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bqLoNQdQmxGb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}